# msCNN-ETC: Enhanced Prediction of Electron Transport Proteins and Complexes Using Protein Language Models and Multiple-Window Separable Convolutional Neural Networks

Electron transport proteins (ETPs) are fundamental to critical biological processes, including photosynthesis and respiration. Accurate identification of ETPs is therefore essential for proteomic analysis. Traditional computational methods, such as those relying on Position-Specific Scoring Matrices (PSSMs), are often computationally expensive and dependent on time-consuming sequence alignments. To address these limitations, we propose msCNN-ETC, a novel alignment-free framework that integrates embeddings from protein language models (PLMs)—specifically ESM-2 and ProtTrans—with a lightweight Multiple-Window Separable Convolutional Neural Network (msCNN). This approach eliminates the need for evolutionary profiles while effectively capturing both semantic and structural information from primary amino acid sequences. Our experiments demonstrate that ProtTrans embeddings yielded the highest performance, achieving an accuracy of 98.94% and a Matthews Correlation Coefficient (MCC) of 0.9592. The ESM-2 model also performed robustly with 98.75% accuracy. Notably, msCNN-ETC significantly outperforms traditional PSSM-based methods and reduces the parameter count by approximately 90% (3.68 million vs. 36.97 million) compared to the previous mCNN architecture. These results highlight the efficacy of combining PLM embeddings with efficient separable CNNs for rapid and accurate protein function prediction, offering significant potential for applications in biotechnology and drug development.

Keywords: electron transport protein, complex, protein language model, multiple-window separable convolutional neural networks, ESM-2, ProtTrans
