{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz-wqG4cKOli",
        "outputId": "cc406234-0e19-4f6c-ce3c-9aaac2880a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gAEOTsG0XSzS",
        "outputId": "962bedb5-a29c-4ab9-a134-05743871c701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ylSdkjJjGRw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "LOG_DIR = '/content/drive/MyDrive/1149108/msCNN-ETC/Logs'\n",
        "os.makedirs(LOG_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "551xVcF0jMjT",
        "outputId": "65db6472-7fe7-426a-9f16-0e6f5e83380e"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "X_train = np.load('/content/drive/MyDrive/1149108/msCNN-ETC/X_train.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/1149108/msCNN-ETC/y_train.npy')\n",
        "X_test = np.load('/content/drive/MyDrive/1149108/msCNN-ETC/X_test.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/1149108/msCNN-ETC/y_test.npy')\n",
        "\n",
        "\n",
        "print(\"data shape:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnYD6_fwdP0d",
        "outputId": "4a9a355f-fd25-4eb7-9030-68ef5679ffe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (6418, 1, 1022, 1280)\n",
            "X_test shape: (1606, 1, 1022, 1280)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train[:, np.newaxis, :, :]  # (samples, 1, height, width)\n",
        "X_test = X_test[:, np.newaxis, :, :]\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b01SdARLgUvL",
        "outputId": "85988657-dcaa-463a-bcb5-3d945e5f1ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float16\n"
          ]
        }
      ],
      "source": [
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A6xvdUN97mD"
      },
      "source": [
        "#Cross-Validation and Independent Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ObFkh_xDq-Pc",
        "outputId": "338243a1-7289-4948-fc00-267c4e9640ed"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tensorflow.keras.saving import register_keras_serializable\n",
        "\n",
        "# === Hyperparameters ===\n",
        "BATCH_SIZE      = 64\n",
        "NUM_CLASSES     = 1\n",
        "EPOCHS          = 50\n",
        "NUM_FILTERS     = 256\n",
        "NUM_HIDDEN      = 1024\n",
        "WINDOW_SIZES    = [8, 12, 16, 20, 24, 28]\n",
        "MAX_SEQ_LENGTH  = 1022\n",
        "EMBEDDING_WIDTH = 1280\n",
        "\n",
        "LOG_MODEL = os.path.join(LOG_DIR, f'MODELS_{WINDOW_SIZES}_{NUM_FILTERS}F_{NUM_HIDDEN}H')\n",
        "os.makedirs(LOG_MODEL, exist_ok=True)\n",
        "\n",
        "@register_keras_serializable()\n",
        "def DeepScan(input_shape=(1, MAX_SEQ_LENGTH, EMBEDDING_WIDTH),\n",
        "             window_sizes=WINDOW_SIZES,\n",
        "             num_filters=NUM_FILTERS,\n",
        "             num_hidden=NUM_HIDDEN,\n",
        "             num_classes=NUM_CLASSES):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    branches = []\n",
        "    for ws in window_sizes:\n",
        "        x = layers.SeparableConv2D(\n",
        "            filters=num_filters,\n",
        "            kernel_size=(1, ws),\n",
        "            strides=(1, 1),\n",
        "            activation='relu',\n",
        "            padding='valid',\n",
        "            depthwise_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "            pointwise_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "            depthwise_initializer='glorot_uniform',\n",
        "            pointwise_initializer='glorot_uniform'\n",
        "        )(inputs)\n",
        "\n",
        "        x = layers.MaxPooling2D(\n",
        "            pool_size=(1, MAX_SEQ_LENGTH - ws + 1),\n",
        "            strides=(1, 1),\n",
        "            padding='valid'\n",
        "        )(x)\n",
        "\n",
        "        x = layers.Flatten()(x)\n",
        "        branches.append(x)\n",
        "\n",
        "    x = layers.Concatenate()(branches)\n",
        "    x = layers.Dropout(0.8)(x)\n",
        "    x = layers.Dense(num_hidden, activation='relu', name='fc1')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='DeepScan')\n",
        "    return model\n",
        "\n",
        "# === Callback on CV folds ===\n",
        "class MetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X_val, y_val, fold):\n",
        "        super().__init__()\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.fold  = fold\n",
        "        self.fold_start_time = time.time()\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_pred_probs  = self.model.predict(self.X_val, batch_size=BATCH_SIZE, verbose=0).ravel()\n",
        "        y_pred_labels = (y_pred_probs >= 0.5).astype(int)\n",
        "\n",
        "        cm = metrics.confusion_matrix(self.y_val, y_pred_labels)\n",
        "        if cm.size == 1:\n",
        "            if y_pred_labels[0] == 1:\n",
        "                TN, FP, FN, TP = 0, 0, cm[0,0], 0\n",
        "            else:\n",
        "                TN, FP, FN, TP = cm[0,0], 0, 0, 0\n",
        "        else:\n",
        "            TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        Sens = TP/(TP+FN) if TP+FN>0 else 0\n",
        "        Spec = TN/(TN+FP) if TN+FP>0 else 0\n",
        "        Acc  = (TP+TN)/(TP+FP+TN+FN) if TP+FP+TN+FN>0 else 0\n",
        "        denom = (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)\n",
        "        MCC = (TP*TN - FP*FN)/math.sqrt(denom) if denom>0 else 0\n",
        "        F1  = 2*TP/(2*TP + FP + FN) if 2*TP+FP+FN>0 else 0\n",
        "\n",
        "        # AUC calculation\n",
        "        fpr, tpr, _ = roc_curve(self.y_val, y_pred_probs)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        epoch_time = time.time() - self.epoch_start\n",
        "        results.loc[len(results)] = [\n",
        "            'CV', self.fold, epoch+1, TP, FP, TN, FN,\n",
        "            Sens, Spec, Acc, MCC, F1, roc_auc,\n",
        "            None, epoch_time, self.model.count_params()\n",
        "        ]\n",
        "\n",
        "class SaveEveryEpochCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, base_dir, stage='CV', fold=None):\n",
        "        super().__init__()\n",
        "        self.base_dir = base_dir\n",
        "        self.stage = stage\n",
        "        self.fold = fold\n",
        "        self.sub_dir = os.path.join(base_dir, stage, f'fold_{fold}' if fold is not None else '')\n",
        "        os.makedirs(self.sub_dir, exist_ok=True)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        filename = f\"{self.stage}_fold{self.fold}_epoch{epoch+1:02d}.keras\" if self.fold is not None else f\"{self.stage}_epoch{epoch+1:02d}.keras\"\n",
        "        path = os.path.join(self.sub_dir, filename)\n",
        "        self.model.save(path)\n",
        "        print(f\"[Saved model] Epoch {epoch+1} saved to {path}\")\n",
        "\n",
        "# === Callback on independent test ===\n",
        "class FinalMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X_test, y_test):\n",
        "        super().__init__()\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "# === DataFrame Column ===\n",
        "results_columns = [\n",
        "    'Stage', 'Fold', 'Epoch', 'TP', 'FP', 'TN', 'FN',\n",
        "    'Sens', 'Spec', 'Acc', 'MCC', 'F1', 'AUC',\n",
        "    'Train_Time', 'Epoch_Time', 'Total_Params'\n",
        "]\n",
        "results = pd.DataFrame(columns=results_columns)\n",
        "\n",
        "# =========================================================\n",
        "# 5-Fold Cross-Validation \n",
        "#   \n",
        "# =========================================================\n",
        "best_epochs = []\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), start=1):\n",
        "    print(f\"\\n=== Fold {fold}/5 ===\")\n",
        "    X_train_fold, X_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    model = DeepScan(window_sizes=WINDOW_SIZES,\n",
        "                     num_filters=NUM_FILTERS,\n",
        "                     num_hidden=NUM_HIDDEN)\n",
        "    model.build((None, 1, MAX_SEQ_LENGTH, EMBEDDING_WIDTH))\n",
        "    model.summary()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    metrics_cb = MetricsCallback(X_val, y_val, fold)\n",
        "    tb_cb = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(LOG_DIR, f'fold_{fold}'))\n",
        "    early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max')\n",
        "    save_cb = SaveEveryEpochCallback(base_dir=LOG_MODEL, stage='CV', fold=fold)\n",
        "    checkpoint_path = os.path.join(LOG_MODEL, f'best_model__{WINDOW_SIZES}_{NUM_FILTERS}F_{NUM_HIDDEN}H_CV_{fold}.keras')\n",
        "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_auc', save_best_only=True, mode='max')\n",
        "\n",
        "    start_fold = time.time()\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[metrics_cb, tb_cb, early_stop_cb, save_cb, checkpoint_cb],\n",
        "        verbose=1,\n",
        "    )\n",
        "    train_time = time.time() - start_fold\n",
        "    results.loc[(results.Stage=='CV') & (results.Fold==fold), 'Train_Time'] = train_time\n",
        "\n",
        "    val_auc_list = history.history.get('val_auc', None)\n",
        "    if val_auc_list is None or len(val_auc_list) == 0:\n",
        "        raise RuntimeError(\"No val_auc found in training history.\")\n",
        "    best_epoch_fold = int(np.argmax(val_auc_list) + 1)\n",
        "    best_epochs.append(best_epoch_fold)\n",
        "    print(f\"[Fold {fold}] Best epoch by val_auc = {best_epoch_fold}, val_auc = {val_auc_list[best_epoch_fold-1]:.4f}\")\n",
        "\n",
        "# Save CV results\n",
        "results_path = os.path.join(\n",
        "    LOG_DIR,\n",
        "    f'training_results_{WINDOW_SIZES}_{NUM_FILTERS}F_{NUM_HIDDEN}H.csv'\n",
        ")\n",
        "results.to_csv(results_path, index=False)\n",
        "print(f\"\\nCV results saved to {results_path}\")\n",
        "\n",
        "# =========================================================\n",
        "# Final training on full TRAIN set with selected epochs\n",
        "# =========================================================\n",
        "final_epochs = int(np.median(best_epochs)) if len(best_epochs) > 0 else EPOCHS\n",
        "final_epochs = max(1, min(final_epochs, EPOCHS))  \n",
        "print(f\"\\nSelected final_epochs (median best epochs from CV) = {final_epochs}\")\n",
        "print(f\"best_epochs per fold = {best_epochs}\")\n",
        "\n",
        "final_model = DeepScan(window_sizes=WINDOW_SIZES,\n",
        "                      num_filters=NUM_FILTERS,\n",
        "                      num_hidden=NUM_HIDDEN)\n",
        "final_model.build((None, 1, MAX_SEQ_LENGTH, EMBEDDING_WIDTH))\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "save_cb = SaveEveryEpochCallback(base_dir=LOG_MODEL, stage='Independent')\n",
        "\n",
        "start_final = time.time()\n",
        "history = final_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=final_epochs,\n",
        "    callbacks=[save_cb],\n",
        "    verbose=1\n",
        ")\n",
        "final_train_time = time.time() - start_final\n",
        "\n",
        "final_model_path = os.path.join(LOG_MODEL, f'final_model__{WINDOW_SIZES}_{NUM_FILTERS}F_{NUM_HIDDEN}H_epochs{final_epochs}.keras')\n",
        "final_model.save(final_model_path)\n",
        "print(f\"\\nFinal model saved to {final_model_path}\")\n",
        "\n",
        "# =========================================================\n",
        "#Independent evaluation\n",
        "# =========================================================\n",
        "t0 = time.time()\n",
        "y_pred_probs  = final_model.predict(X_test, batch_size=BATCH_SIZE, verbose=0).ravel()\n",
        "epoch_time = time.time() - t0\n",
        "y_pred_labels = (y_pred_probs >= 0.5).astype(int)\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "if cm.size == 1:\n",
        "    if y_pred_labels[0] == 1:\n",
        "        TN, FP, FN, TP = 0, 0, cm[0,0], 0\n",
        "    else:\n",
        "        TN, FP, FN, TP = cm[0,0], 0, 0, 0\n",
        "else:\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "Sens = TP/(TP+FN) if TP+FN>0 else 0\n",
        "Spec = TN/(TN+FP) if TN+FP>0 else 0\n",
        "Acc  = (TP+TN)/(TP+FP+TN+FN) if TP+FP+TN+FN>0 else 0\n",
        "denom = (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)\n",
        "MCC = (TP*TN - FP*FN)/math.sqrt(denom) if denom>0 else 0\n",
        "F1  = 2*TP/(2*TP + FP + FN) if 2*TP+FP+FN>0 else 0\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "results.loc[len(results)] = [\n",
        "    'Independent', 'Final', final_epochs, TP, FP, TN, FN,\n",
        "    Sens, Spec, Acc, MCC, F1, roc_auc,\n",
        "    final_train_time, epoch_time, final_model.count_params()\n",
        "]\n",
        "\n",
        "# Save final results\n",
        "results.to_csv(results_path, index=False)\n",
        "print(f\"\\nFinal results saved to {results_path}\")\n",
        "\n",
        "print(\"\\n=== Independent Test (X_test) ===\")\n",
        "print(f\"AUC={roc_auc:.4f} | Acc={Acc:.4f} | Sens={Sens:.4f} | Spec={Spec:.4f} | MCC={MCC:.4f} | F1={F1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "QhybZNj7-BWg",
        "DBqB-BCTW-Ua"
      ],
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
